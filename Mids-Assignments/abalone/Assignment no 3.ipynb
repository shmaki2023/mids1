{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af159345",
   "metadata": {},
   "source": [
    "# *Assignment no 3*\n",
    "## *Name - Kiran Shete*\n",
    "## *Roll no - 33568*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5720481d",
   "metadata": {},
   "source": [
    "## *Including the libaries*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "335e463d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29d18ac",
   "metadata": {},
   "source": [
    "## *Load the Data*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23f25f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"http://archive.ics.uci.edu/ml/machine-learning-databases/abalone/abalone.data\"\n",
    "names = ['sex', 'length', 'diameter', 'height', 'whole_weight', 'shucked_weight', \n",
    "         'viscera_weight', 'shell_weight', 'rings']\n",
    "dataset = pd.read_csv(url, names=names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56cf90a",
   "metadata": {},
   "source": [
    "# *Split the dataset into training and testing sets*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0767ec27",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.get_dummies(dataset, columns=['sex'])\n",
    "\n",
    "X = dataset.drop(['rings'], axis=1)\n",
    "y = dataset['rings']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664c9027",
   "metadata": {},
   "source": [
    "# *Normalize the features using standard scaler*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a99fa6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3582f2e9",
   "metadata": {},
   "source": [
    "# *Train a linear regression model*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79233afa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_model = LinearRegression()\n",
    "reg_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a17439a3",
   "metadata": {},
   "source": [
    "# *Predict the number of rings for the test set and evaluate the Model using mean square error*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "398b98fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 4.738987418893083\n",
      "[ 8.32837392  9.25024892 11.03149892 12.93774892  7.06274892  9.81274892\n",
      "  9.03149892 12.34399892 13.43774892 11.34399892  7.18774892  7.84399892\n",
      " 10.00024892 10.50024892  9.21899892 11.48462392 12.65649892  8.68774892\n",
      "  9.43774892  7.98462392 11.92212392 12.18774892  5.73462392  7.87524892\n",
      "  8.93774892 10.78149892  9.65649892  5.82837392 11.84399892 10.59399892\n",
      " 11.53149892 11.62524892  7.51587392  6.59399892  7.06274892 11.07837392\n",
      "  7.45337392 12.67212392 11.34399892  8.00024892  5.14087392 10.70337392\n",
      "  9.65649892  7.20337392 14.98462392 12.50024892  8.06274892  7.07837392\n",
      "  9.60962392  7.39087392  7.73462392  8.90649892  8.29712392 10.75024892\n",
      " 11.07837392  6.31274892 13.46899892  9.57837392  8.81274892  9.07837392\n",
      " 10.68774892  8.28149892 10.31274892  9.21899892 11.81274892  8.01587392\n",
      "  7.28149892  9.34399892 13.53149892  8.57837392 12.70337392 11.37524892\n",
      " 12.21899892  6.82837392 12.26587392 12.28149892 10.46899892 12.87524892\n",
      " 11.03149892 11.25024892  9.60962392 12.84399892 14.68774892  8.40649892\n",
      "  7.12524892  7.03149892 10.31274892 14.00024892 13.25024892  7.06274892\n",
      " 10.28149892 20.21899892 17.34399892 10.75024892  9.65649892  9.14087392\n",
      " 10.56274892  7.15649892  7.56274892 10.75024892  5.07837392 11.96899892\n",
      "  6.39087392 13.37524892 16.28149892 11.06274892  7.92212392  6.45337392\n",
      " 11.25024892 11.17212392  6.71899892 10.46899892  8.39087392  9.59399892\n",
      "  6.14087392 11.51587392  9.68774892 12.59399892  8.95337392  9.32837392\n",
      "  6.56274892  7.03149892  8.81274892 13.28149892  9.95337392  8.37524892\n",
      " 10.62524892 11.78149892  8.59399892 12.00024892  9.93774892  5.67212392\n",
      "  9.65649892 13.89087392  8.59399892 12.12524892  5.95337392 13.28149892\n",
      " 11.12524892  9.23462392  8.21899892  9.01587392  6.75024892  8.18774892\n",
      " 13.31274892  6.95337392 10.06274892  9.84399892  7.51587392  9.00024892\n",
      " 12.78149892 12.65649892  6.48462392  8.62524892 10.12524892 12.46899892\n",
      "  6.57837392 11.51587392  7.03149892  8.65649892 12.25024892 11.09399892\n",
      " 12.18774892 15.34399892  7.18774892  7.93774892 11.98462392  9.45337392\n",
      "  8.64087392  9.12524892  7.51587392  9.28149892  5.93774892 14.06274892\n",
      " 12.00024892 15.12524892  8.20337392 11.81274892  5.76587392 10.18774892\n",
      "  7.14087392  5.29712392 11.68774892  9.37524892  7.57837392  9.79712392\n",
      " 11.56274892  9.39087392 11.00024892  8.43774892 14.00024892  9.50024892\n",
      "  9.51587392  8.57837392 10.00024892  8.56274892  9.68774892 11.25024892\n",
      " 11.06274892  9.78149892 12.37524892  6.51587392  9.53149892  7.26587392\n",
      " 10.31274892 10.82837392 11.84399892 11.48462392 10.31274892  9.54712392\n",
      "  8.53149892 11.51587392  9.68774892  8.10962392  9.92212392 12.71899892\n",
      "  7.45337392  8.96899892 11.39087392 13.15649892 10.81274892  9.93774892\n",
      " 11.59399892  9.54712392 11.50024892  6.93774892  9.75024892  7.46899892\n",
      "  8.54712392  6.75024892  5.92212392  8.04712392 16.32837392 11.40649892\n",
      "  7.09399892  6.54712392 12.50024892  9.25024892  7.93774892 11.53149892\n",
      "  9.17212392  9.17212392 10.00024892  8.56274892  8.03149892 11.56274892\n",
      " 10.65649892  8.76587392 11.18774892 13.68774892 11.71899892 10.12524892\n",
      "  8.43774892  8.67212392  8.53149892 10.40649892 15.34399892  8.26587392\n",
      "  8.85962392 11.53149892 10.75024892  8.50024892 12.15649892 13.92212392\n",
      " 10.62524892 11.35962392 10.21899892 10.71899892  7.17212392  9.75024892\n",
      " 10.14087392  8.09399892  7.62524892 11.96899892 10.09399892  5.07837392\n",
      " 13.68774892  7.32837392  5.89087392 10.90649892 12.00024892 14.56274892\n",
      "  9.50024892  9.46899892  8.39087392  7.65649892 11.76587392  8.71899892\n",
      " 10.92212392  7.62524892  8.10962392 11.39087392  9.00024892  9.46899892\n",
      " 10.15649892  8.92212392  9.90649892  9.96899892 11.75024892 12.14087392\n",
      " 10.62524892  9.81274892 10.09399892 11.01587392 10.50024892 10.18774892\n",
      "  9.59399892  7.81274892  9.79712392  9.10962392  9.78149892  8.87524892\n",
      " 16.71899892  9.42212392  7.23462392  7.70337392  9.26587392 10.76587392\n",
      " 10.28149892  7.84399892 12.82837392 10.25024892 10.28149892  7.87524892\n",
      "  9.96899892 10.15649892 11.06274892 10.48462392 11.00024892  9.29712392\n",
      " 10.10962392  8.81274892  8.92212392 10.20337392  8.87524892 12.98462392\n",
      " 10.00024892 13.82837392  9.84399892  6.53149892  6.79712392  9.12524892\n",
      "  8.46899892 12.40649892  9.06274892 12.29712392  8.87524892 10.81274892\n",
      "  7.54712392  9.37524892  9.23462392 10.03149892 10.21899892 10.31274892\n",
      " 13.28149892  7.10962392  6.95337392 10.78149892 12.18774892 10.06274892\n",
      "  7.21899892 13.04712392  9.21899892  6.00024892 11.56274892  9.42212392\n",
      " 11.07837392 11.70337392 10.81274892  8.71899892 10.71899892  6.75024892\n",
      " 11.50024892  9.56274892 12.45337392  8.09399892 11.03149892  6.25024892\n",
      "  7.79712392 11.39087392 12.43774892  9.03149892  6.56274892 14.39087392\n",
      " 10.68774892  7.31274892 14.34399892 11.50024892  9.95337392 10.07837392\n",
      " 10.06274892 11.09399892  9.54712392 15.90649892 13.25024892  9.35962392\n",
      " 13.87524892  9.43774892 10.15649892 12.37524892  9.96899892 12.43774892\n",
      "  8.25024892  6.92212392  8.42212392  8.23462392 10.37524892 12.14087392\n",
      "  6.50024892 10.00024892  9.31274892 11.43774892  9.59399892 10.09399892\n",
      " 10.40649892  6.29712392 10.21899892  9.56274892 11.53149892  8.95337392\n",
      " 10.59399892  9.29712392 13.14087392 11.18774892  7.78149892  9.68774892\n",
      " 13.04712392  5.42212392 11.20337392  9.40649892  6.00024892  5.78149892\n",
      "  9.50024892 16.34399892  9.62524892  7.39087392  6.32837392 11.96899892\n",
      "  9.25024892  8.21899892 13.65649892 12.50024892 10.20337392  9.68774892\n",
      " 11.65649892  8.23462392 10.71899892  8.09399892 10.54712392 11.93774892\n",
      " 11.78149892  7.15649892  9.43774892 10.59399892  5.32837392 13.56274892\n",
      " 15.90649892  8.60962392 11.15649892 11.57837392  9.84399892  7.37524892\n",
      "  9.85962392  7.32837392 10.75024892 11.62524892  7.93774892  8.60962392\n",
      "  7.62524892  9.40649892 10.62524892 10.62524892  8.46899892  8.28149892\n",
      "  7.03149892 12.29712392 13.65649892 11.71899892  9.15649892  4.98462392\n",
      "  6.54712392  9.28149892 10.03149892 12.31274892  8.28149892 11.03149892\n",
      "  7.98462392 10.71899892 12.76587392  7.65649892  9.78149892  8.76587392\n",
      "  9.25024892 10.45337392  8.98462392  9.73462392  9.45337392 10.65649892\n",
      " 10.98462392 13.96899892 11.43774892  6.35962392 12.68774892 11.45337392\n",
      "  9.39087392 12.12524892  9.15649892 10.25024892  8.26587392 16.90649892\n",
      "  9.71899892  8.28149892  9.25024892  6.53149892 10.31274892  9.40649892\n",
      "  9.87524892  7.90649892 10.71899892  9.17212392 10.00024892 11.17212392\n",
      " 10.06274892 12.50024892  8.53149892  7.26587392  9.10962392 10.01587392\n",
      " 10.56274892  6.81274892 10.81274892 12.28149892 12.43774892  8.43774892\n",
      " 11.48462392  9.57837392 11.31274892  7.70337392  9.54712392  9.73462392\n",
      " 10.00024892 10.56274892 10.93774892  6.46899892 12.96899892  7.46899892\n",
      "  9.81274892 10.29712392 10.71899892 18.62524892 10.21899892 10.15649892\n",
      " 11.51587392 12.09399892 12.65649892  8.39087392 10.93774892  9.93774892\n",
      " 14.25024892 13.25024892  6.75024892  9.03149892  8.50024892 16.81274892\n",
      "  8.15649892  9.09399892  8.59399892  9.89087392 14.34399892  8.64087392\n",
      " 10.01587392 10.18774892 15.75024892  9.06274892 11.28149892  5.32837392\n",
      "  9.28149892  7.09399892 11.40649892 13.50024892  8.90649892 10.29712392\n",
      "  7.96899892  8.71899892  8.89087392 10.32837392 18.15649892  9.01587392\n",
      "  4.70337392  9.82837392 10.15649892  9.68774892  7.15649892  9.21899892\n",
      "  9.50024892  8.45337392 10.01587392  8.85962392 10.62524892  3.93774892\n",
      "  5.46899892 12.03149892  6.14087392  5.93774892  9.06274892  7.92212392\n",
      " 10.20337392 10.67212392 11.43774892  9.96899892  8.84399892 11.50024892\n",
      "  8.62524892 13.28149892  9.53149892  8.50024892  9.50024892 17.65649892\n",
      " 12.17212392  8.85962392  7.45337392 10.37524892 10.73462392 12.93774892\n",
      " 10.71899892  8.82837392  7.42212392  9.89087392  9.00024892 11.56274892\n",
      " 11.03149892 10.70337392 12.57837392  9.67212392 17.85962392  5.87524892\n",
      "  8.31274892  5.78149892 10.15649892 14.25024892 10.56274892 10.04712392\n",
      "  6.31274892 13.59399892 10.26587392  7.53149892  9.45337392  7.84399892\n",
      " 10.98462392  8.50024892 13.84399892 11.03149892 10.25024892  8.28149892\n",
      "  7.18774892  8.76587392  9.42212392  8.96899892 11.96899892  8.43774892\n",
      "  9.28149892  7.03149892 10.62524892  6.14087392  6.04712392 11.62524892\n",
      "  9.79712392  6.25024892  8.81274892 10.25024892 11.53149892  7.75024892\n",
      "  9.15649892  8.78149892 12.84399892  6.82837392 10.95337392 14.18774892\n",
      "  9.04712392  7.45337392 10.34399892  6.18774892  9.67212392  8.34399892\n",
      "  8.42212392 11.12524892 11.56274892 15.28149892 12.51587392 12.43774892\n",
      " 14.90649892 11.09399892  9.20337392 12.67212392 17.57837392  9.32837392\n",
      "  9.96899892  7.70337392  9.71899892  9.12524892 13.64087392 10.06274892\n",
      " 11.46899892  9.84399892  4.59399892 12.43774892 13.40649892 12.45337392\n",
      "  5.79712392  7.39087392 10.15649892  9.75024892 10.37524892  8.14087392\n",
      "  8.84399892 12.12524892  6.17212392 18.90649892 10.54712392  8.40649892\n",
      "  9.68774892  7.67212392 11.93774892 10.35962392  9.00024892  9.39087392\n",
      " 12.31274892  7.34399892  9.40649892  7.18774892  8.90649892  9.79712392\n",
      " 11.40649892 14.18774892 10.28149892  8.75024892 10.76587392 10.28149892\n",
      "  9.31274892  9.00024892 11.06274892 11.46899892 10.03149892 10.31274892\n",
      " 11.73462392  9.17212392  9.56274892 11.06274892 10.50024892  7.31274892\n",
      " 13.48462392 11.31274892 10.68774892  6.46899892  9.53149892  7.26587392\n",
      "  6.70337392 10.48462392  9.87524892  8.43774892 10.64087392 11.12524892\n",
      "  6.42212392 11.17212392 10.09399892 11.89087392 10.31274892 12.71899892\n",
      " 14.93774892 14.01587392 11.75024892  9.90649892 11.68774892  9.87524892\n",
      "  9.40649892  9.87524892  6.98462392  7.06274892  9.00024892  6.09399892\n",
      "  6.98462392  9.81274892  9.78149892  9.68774892  7.43774892 14.45337392\n",
      "  7.57837392 12.31274892  5.78149892  9.92212392 10.87524892 11.07837392\n",
      " 11.59399892 10.53149892  8.14087392 11.75024892 11.34399892  9.40649892\n",
      " 10.71899892 13.21899892  9.15649892 12.84399892 10.01587392 11.70337392\n",
      "  7.17212392 11.89087392  9.37524892  9.43774892 11.51587392  6.43774892\n",
      " 20.04712392 11.59399892  8.79712392 10.50024892  9.93774892  6.31274892\n",
      "  7.10962392  7.81274892  8.40649892 10.93774892 10.07837392  9.34399892\n",
      " 10.01587392  4.50024892 12.00024892 13.43774892  7.79712392 11.03149892\n",
      " 11.45337392 10.81274892 11.68774892  7.51587392 11.25024892  8.78149892\n",
      "  9.25024892 11.39087392]\n"
     ]
    }
   ],
   "source": [
    "y_pred = reg_model.predict(X_test)\n",
    "print('Mean Squared Error:', mean_squared_error(y_test, y_pred))\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a37ba835",
   "metadata": {},
   "source": [
    "# *Train a random forest regression model and predict the number of rings for the test set*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af86fdd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RandomForestRegressor()\n",
    "rf_model.fit(X_train, y_train)\n",
    "y_pred = rf_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f41274",
   "metadata": {},
   "source": [
    "# *Evaluate the model using mean squared error and R-squared and define a threshold*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec0f391e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 4.46791423444976\n",
      "R-squared: 0.5109913330129243\n"
     ]
    }
   ],
   "source": [
    "print('Mean Squared Error:', mean_squared_error(y_test, y_pred))\n",
    "print('R-squared:', r2_score(y_test, y_pred))\n",
    "\n",
    "# predict the number of rings as a classification problem\n",
    "# define a threshold for the number of rings\n",
    "threshold = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c8b551",
   "metadata": {},
   "source": [
    "# *label the data points as either having fewer rings or more rings than the threshold*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00e3fcd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_train_class = np.where(y_train < threshold, 0, 1)\n",
    "y_test_class = np.where(y_test < threshold, 0, 1)\n",
    "\n",
    "# train a logistic regression model\n",
    "log_model = LogisticRegression()\n",
    "log_model.fit(X_train, y_train_class)\n",
    "\n",
    "# predict the labels for the test set\n",
    "y_pred_class = log_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1923aa0",
   "metadata": {},
   "source": [
    "# *Evaluate the model using classification report and accuracy score and predict the labels for the test set*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ee163b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.79      0.78       423\n",
      "           1       0.78      0.77      0.78       413\n",
      "\n",
      "    accuracy                           0.78       836\n",
      "   macro avg       0.78      0.78      0.78       836\n",
      "weighted avg       0.78      0.78      0.78       836\n",
      "\n",
      "Accuracy: 0.7799043062200957\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(classification_report(y_test_class, y_pred_class))\n",
    "print('Accuracy:', accuracy_score(y_test_class, y_pred_class))\n",
    "\n",
    "svm_model = SVC()\n",
    "svm_model.fit(X_train, y_train_class)\n",
    "\n",
    "y_pred_class = svm_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af907ab2",
   "metadata": {},
   "source": [
    "# *Evaluate the model using classification report and accuracy score and predict the labels for the test set*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "57c1c89e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.75      0.78       423\n",
      "           1       0.76      0.82      0.79       413\n",
      "\n",
      "    accuracy                           0.78       836\n",
      "   macro avg       0.78      0.78      0.78       836\n",
      "weighted avg       0.78      0.78      0.78       836\n",
      "\n",
      "Accuracy: 0.7822966507177034\n",
      "[0 1 1 1 0 1 1 1 1 1 0 0 1 1 0 1 1 0 1 0 1 1 0 0 1 1 0 0 1 1 1 1 0 0 0 1 0\n",
      " 1 1 0 1 1 0 0 1 1 0 0 1 0 0 0 0 1 1 0 1 1 0 0 0 0 0 0 1 0 0 0 1 0 1 1 1 0\n",
      " 1 1 1 1 1 1 0 1 1 0 0 0 1 1 1 0 1 1 1 1 0 0 1 0 0 1 0 1 0 1 1 1 0 0 1 1 0\n",
      " 0 0 0 0 1 0 1 0 1 0 0 0 1 1 0 1 1 0 1 0 0 1 1 0 1 0 1 1 0 0 0 0 0 1 0 1 0\n",
      " 0 1 1 1 0 0 1 1 0 1 0 1 1 1 1 1 0 1 1 0 0 1 0 0 0 1 1 1 0 1 0 1 0 0 1 0 0\n",
      " 0 1 0 0 1 1 1 1 0 0 0 1 1 1 1 1 0 1 0 0 1 1 1 1 0 1 1 0 0 0 1 0 0 1 1 1 0\n",
      " 1 1 1 0 1 0 0 0 0 0 1 1 0 0 1 1 0 1 1 1 1 0 0 1 1 0 1 1 1 1 0 0 0 1 1 0 0\n",
      " 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 0 0 1 0 0 1 1 1 1 1 0 0 1 0 1 0 0 1 0 1 0 0\n",
      " 1 0 1 1 1 1 1 0 1 1 0 0 0 0 1 1 1 1 0 0 1 1 0 0 1 0 0 0 1 1 1 1 1 1 0 0 0\n",
      " 1 0 1 0 1 0 0 0 0 0 1 0 1 0 1 0 0 0 1 1 1 1 0 0 1 1 1 0 1 0 0 1 0 1 1 1 0\n",
      " 1 0 1 0 1 0 1 0 0 1 1 1 0 1 1 0 1 1 0 1 0 1 1 1 1 0 1 0 1 1 0 1 0 0 0 0 1\n",
      " 1 0 1 0 1 1 1 1 1 1 0 1 0 1 0 1 1 0 0 1 0 1 0 0 0 0 1 1 0 0 1 0 0 1 1 1 1\n",
      " 1 0 1 0 1 1 1 0 1 1 0 1 1 0 1 1 0 0 0 0 1 1 0 0 0 0 1 1 0 0 0 1 1 1 0 0 0\n",
      " 0 1 1 0 1 0 1 1 0 1 0 0 1 0 0 0 1 1 1 1 0 1 1 0 1 1 1 0 1 1 0 0 0 1 0 1 0\n",
      " 1 1 1 1 1 1 1 0 0 1 1 0 1 1 1 0 1 1 1 0 1 1 1 1 1 0 1 0 1 0 1 1 0 1 1 1 1\n",
      " 0 1 0 1 1 0 0 1 1 0 1 0 0 1 0 0 0 1 0 1 0 0 0 1 1 0 1 0 1 0 1 1 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 1 0 1 0 0 1 1 1 1 0 1 0 1 0 0 0 1 1 0 0 1 1 1 1 0 0 0 0\n",
      " 1 1 1 1 0 1 0 0 0 1 1 1 0 0 1 1 0 0 0 0 1 1 1 1 0 0 0 1 0 1 0 0 0 1 0 0 1\n",
      " 1 0 0 0 1 0 1 0 1 0 1 1 0 0 0 0 0 0 0 1 1 1 1 1 1 1 0 1 1 0 1 0 1 0 1 1 1\n",
      " 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 1 0 1 0 1 1 1 0 1 0 0 0 0 0 1 1 1 0 1 1 0 0\n",
      " 1 1 0 0 1 0 0 1 1 0 1 0 0 0 1 0 0 0 0 0 1 1 0 1 1 1 1 1 1 1 1 1 1 0 0 0 0\n",
      " 0 0 0 0 1 1 0 0 1 0 1 0 1 0 1 1 1 0 1 1 1 1 1 0 1 0 1 0 1 0 1 1 0 1 1 0 1\n",
      " 0 0 0 0 0 1 1 0 1 0 1 1 0 1 1 1 1 0 1 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(classification_report(y_test_class, y_pred_class))\n",
    "print('Accuracy:', accuracy_score(y_test_class, y_pred_class))\n",
    "\n",
    "# train a random forest classifier model\n",
    "rfc_model = RandomForestClassifier()\n",
    "rfc_model.fit(X_train, y_train_class)\n",
    "\n",
    "y_pred_class = rfc_model.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b010b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
